{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb5dffb2",
   "metadata": {},
   "source": [
    "**Robotic Mapping with LiDAR Data |** Linear Transformations\n",
    "============================================================\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0bbb83",
   "metadata": {},
   "source": [
    "ROB 101: Computational Linear Algebra | University of Michigan, Department of Robotics\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aeac1a1",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a73140",
   "metadata": {},
   "source": [
    "**Please read carefully. Ask questions if you are unsure.**\n",
    "-----------------------------------------------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec229ef",
   "metadata": {},
   "source": [
    "We use an auto-grader to check your work. If you invent new notation (such as, new variable names) for yourself, you will mess up the auto-grader and receive no points. We will NOT do manual regrades because of failure to use the requested variable names.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041479ba",
   "metadata": {},
   "source": [
    "Do not reinitialize variables and data provided for you. Please just run the cells when information is initialized for you. DO NOT RETYPE IT unless it is in a static cell (a cell that has no run button).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712f7cdd",
   "metadata": {},
   "source": [
    "Not all tests are visible to you. Just because you have passed a test, doesn‚Äôt mean you will get full credit. Take some time to understand what it is your code is doing and what should output so you can check your answers before submission.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f96c792",
   "metadata": {},
   "source": [
    "### IllumiDesk Tips\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e76aa9",
   "metadata": {},
   "source": [
    "* Within code cells, click the blue play button on the left to run the code.\n",
    "* In the upper right, you can see if your kernel is connected. That is a dropdown menu that has additional functionality to ‚Äúdisconnect‚Äù, ‚Äúrestart‚Äù, and ‚Äúclear all outputs‚Äù of the Kernel. None of these buttons will delete your work.\n",
    "* Do not forget that code runs sequentially!\n",
    "* Selecting the clipboard icon on the right will allow you to skip to different parts of this document without scrolling.\n",
    "* Upon completion of an assignment, click the blue ‚ÄúSubmit‚Äù button in the upper right.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869f90cb",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316cfaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run this cell so you can use the necessary package(s).\n",
    "using LinearAlgebra, Random, Plots, DelimitedFiles\n",
    "\n",
    "default(fmt = :png)\n",
    "\n",
    "for (root, dirs, files) in walkdir(\"/home/jovyan/\")\n",
    "  println(\"Root: \", root)\n",
    "  println(\"Directories: \", dirs)\n",
    "  println(\"Files: \", files)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5876f1",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67941516",
   "metadata": {},
   "source": [
    "Task 3\n",
    "======\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d1a5e9",
   "metadata": {},
   "source": [
    "Now that you have seen the power of matrix transformations in 2D, let's move on to the more challenging case of 3D.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67c04f6",
   "metadata": {},
   "source": [
    "In this task, you will plot the raw point cloud data obtained from Cassie's LiDAR over a period of 1 second. Running Cassie's LiDAR at 10 Hz, we have collected 10 different scans of LiDAR data over the one second interval and combined them into one big file. You will see how huge the file is while working on this problem and appreciate what it means to do math at scale!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bba3205",
   "metadata": {},
   "source": [
    "The collected data is in the frame of the LiDAR, which moves with the robot. To simplify the data management for you (because data management is not a focus of ROB 101), we have built a data parsing function that organizes the information from a slew of comma separated values (csv) files into different meaningful arrays. The function `data_parser()` will parse each second of your data set into five different arrays that you will need for this problem.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26babb0",
   "metadata": {},
   "source": [
    "The input to the `data_parser()` is the **time interval id number** of the data set, with ùëñùëë‚àà\\{9,10,11,12,13\\} which gives the identity of a data set (*the corresponding time*). It must be passed as an argument to the function and **the data returned should be saved in the same order that it is produced by the parser**. See the second cell for an example function call.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c64f1fc",
   "metadata": {},
   "source": [
    "The different arrays that will contain the data are given as:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be27b34",
   "metadata": {},
   "source": [
    "* `pointcloud_data`: This has the xyz coordinates of the point cloud\n",
    "* `Intensity_data`: The LiDAR Intensity data\n",
    "* `R`: Rotation Matrix\n",
    "* `t`: Translation vector\n",
    "* `pose`: Gives the true xyz position (column 1) and orientation (column 2) of the robot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1a2997",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the data parser and helper functions block. \n",
    "\n",
    "function data_parser(id)\n",
    "    # load point cloud from file\n",
    "    \n",
    "    #points = readdlm(string(\"data/Frame_\", string(id),\"/pointcloud_\", string(id),\".csv\"),',');\n",
    "    points = readdlm(string(\"pointcloud\",string(id),\".csv\"),',');\n",
    "    pointcloud_data = points[1:3,:]; # xyz\n",
    "    Intensity_data = points[4,:]; # intensity\n",
    "    \n",
    "    # load the different transformation from the file, connect \n",
    "    # with the information learned in Task 1 \n",
    "   \n",
    "  #Transformations = readdlm(string(\"data/Frame_\", string(id),\"/Transformations_\", string(id),\".csv\"),',');\n",
    "  Transformations = readdlm(string(\"Transformations_\",string(id),\".csv\"),',');\n",
    "    R = Transformations[:,1:3]; # rotation\n",
    "    t = Transformations[:,4]; # translation\n",
    "    \n",
    "    # Also get the position of the the robot from another file \n",
    "    \n",
    "  #pose = readdlm(string(\"data/Frame_\",string(id),\"/Position_\",string(id),\".csv\"),',');\n",
    "    pose = readdlm(string(\"Position_\",string(id),\".csv\"),',');\n",
    "    return (pointcloud_data, Intensity_data, R, t, pose)\n",
    "end\n",
    "\n",
    "\n",
    "#= \n",
    "The next function will apply a homogeneous transformation to a matrix of points\n",
    "\n",
    "This is the exact same process you were using in Tasks 1 and 2,\n",
    "where we appended ones to the data, apply the homogeneous transformation, \n",
    "and then remove the ones after applying the transformation. \n",
    "This is how one organizes code to work at scale: you build functions! \n",
    "=#\n",
    "\n",
    "function affine_transform(points, H)\n",
    "    # Make a copy of the original points and append 1 to each point, \n",
    "    # (Homogenizing)\n",
    "    transformed_p = [copy(points); ones(1,size(points,2))];\n",
    "    \n",
    "    # Transform 3D points, looping over all points and multiplying \n",
    "    # the Transformation matrix, exactly like Task 1!\n",
    "    transformed_p = H * transformed_p\n",
    "    \n",
    "    # Remember to return the de-homogenized array, i.e.,\n",
    "    # transformed_points should have same size as input points     \n",
    "    return transformed_p[1:3,:];\n",
    "end\n",
    "\n",
    "#= \n",
    "A function to get robot heading at its position, this is more \n",
    "of a hack that we use to get the arrow of our position estimate when plotting, \n",
    "you are definitely not expected to understand it. \n",
    "=#\n",
    "\n",
    "function robot_arrow(pose)\n",
    "    position = pose[:,1]; # position\n",
    "    (roll,pitch,yaw) = pose[:,2]; # orientation\n",
    "    \n",
    "    # extract rotation axis! \n",
    "    u = [1*cos(yaw-pi/2)]\n",
    "    v = [1*sin(yaw-pi/2)]\n",
    "    return (position, u, v)\n",
    "end\n",
    "\n",
    "#= \n",
    "Define the viewing window size \n",
    "for setting x and y axis limits, \n",
    "and other plotting parameters\n",
    "=#\n",
    "window_size = 15\n",
    "min_x = -window_size\n",
    "min_y = -window_size\n",
    "max_y = window_size\n",
    "min_z = 0\n",
    "max_z = 2*window_size\n",
    "max_x = window_size;\n",
    "limits = ((min_x, max_x), (min_y, max_y), (min_z, max_z));\n",
    "\n",
    "\n",
    "#=\n",
    "    This function generates a 3D Point Cloud Plot\n",
    "    Mandatory parameters are\n",
    "                        xdata -> x coordinates\n",
    "                        ydata -> y coordinates\n",
    "                        zdata -> z coordinates\n",
    "                        limits -> tuple of coordinate limits\n",
    "                        color -> pointcloud color\n",
    "=#\n",
    "function plot_3D_pointcloud(xdata::Vector{Float64}, ydata::Vector{Float64}, zdata::Vector{Float64}, \n",
    "           limits, color::Vector{Float64};\n",
    "            seriestype=:scatter3d, markersize=0.1, camera=(0,90), dpi=1080,\n",
    "            markercolor=cgrad(:rainbow, rev=true), background_color=:black, \n",
    "            foreground_color=:black, legend=false, aspect_ratio=0.75, new=false)\n",
    "    fxn = new ? plot : plot!\n",
    "    fxn(xdata, ydata, zdata, xlims=limits[1], ylims=limits[2], zlims=limits[3], \n",
    "    seriestype=seriestype, markersize=markersize, camera=camera, dpi=dpi,\n",
    "    markercolor=markercolor, marker_z=color, background_color=background_color,\n",
    "    foreground_color=foreground_color, legend=legend, aspect_ratio=aspect_ratio,\n",
    "    markerstrokewidth=0.001) \n",
    "end\n",
    "#=\n",
    "    This function plots the robot in 2D as a quiver\n",
    "    Mandatory parameters are\n",
    "                        xpos -> x coordinate of robot\n",
    "                        ypos -> y coordinate of robot \n",
    "                        limits -> tuple of coordinate limits\n",
    "                        gradient -> robot orientation (u,v)\n",
    "=#\n",
    "function plot_2D_robot(xpos::Vector{Float64}, ypos::Vector{Float64}, limits, gradient;\n",
    "        seriestype=:quiver, projection=\"3d\", arrow=(10,10), camera=(0,90), dpi=1080,\n",
    "        background_color=:black, foreground_color=:black, legend=false, aspect_ratio=1, \n",
    "        seriescolor=:white, new=false)\n",
    "    fxn = new ? plot : plot!\n",
    "    fxn(xpos, ypos, seriescolor=seriescolor, seriestype=seriestype, projection=projection, \n",
    "        gradient=gradient, arrow=arrow, xlims=limits[1], ylims=limits[2], zlims=limits[3], \n",
    "        camera=camera, dpi=dpi, background_color=background_color, \n",
    "        foreground_color=foreground_color, legend=legend, aspect_ratio=aspect_ratio)\n",
    "end\n",
    "\n",
    "\n",
    "#=\n",
    "    This function generates a 3D Point Cloud Plot\n",
    "    Mandatory parameters are\n",
    "                        xpos -> x coordinate of robot\n",
    "                        ypos -> y coordinate of robot\n",
    "                        zpos -> z coordinate of robot\n",
    "=#\n",
    "function plot_3D_robot(xpos::Vector{Float64}, ypos::Vector{Float64}, zpos::Vector{Float64}; \n",
    "                    markersize=4, seriestype=:scatter3d, seriescolor=:white, new=false)\n",
    "    fxn = new ? plot : plot!\n",
    "    fxn(xpos, ypos, zpos, seriescolor=seriescolor, markersize=markersize, seriestype=seriestype)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c275a65",
   "metadata": {},
   "source": [
    "The next cell reads the raw point cloud in the last data collection instant, which is at time 13 seconds (`id = 13`). As discussed before, the function gives us point cloud data, intensity data, the rotation matrix `R`, the translation vector `t`, and finally an estimate of the robot's pose, that is, its position and orientation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63483603",
   "metadata": {},
   "outputs": [],
   "source": [
    "#= \n",
    "Example call to the function to get the data \n",
    "at time  13 seconds of data collection\n",
    "=#\n",
    "\n",
    "# set the id number\n",
    "id = 13\n",
    "\n",
    "# parse the data and save it into different arrays\n",
    "(point_data, intensity_data, R, t, pose) = data_parser(id)\n",
    "\n",
    "# Lets see the size of the pointcloud and appreciate the challenge \n",
    "# of the problem at hand\n",
    "\n",
    "# Can you say, six hundred ninety six thousand and four hundred ninety six columns? And \n",
    "# that is just for one second of data collected by Cassie. Now you see\n",
    "# why Robotics needs math done at scale! \n",
    "size(point_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a002d07",
   "metadata": {},
   "source": [
    "Task 3, Part A\n",
    "--------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a668779",
   "metadata": {},
   "source": [
    "As mentioned earlier, the LiDAR data is collected in the frame of the LiDAR while the robot is moving. Hence, each frame of LiDAR data is taken from a different position and orientation of the robot. This is analogous to you walking and simultaneously taking photos (not video) and then you trying to overlay the photos to create a single image. What a mess!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c76c0d",
   "metadata": {},
   "source": [
    "To underline the importance of keeping track of the position and orientation of Cassie while it is moving, we are going to overlay multiple LiDAR scans **without transforming** them to a common coordinate system (which we call a world frame). We are deliberately going to make a mess of things. You will see multiple images of something, like you are seeing double or triple!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367c1357",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We skip half of the data to shorten the time\n",
    "start_index = 9\n",
    "end_index  = 13\n",
    "\n",
    "plot()\n",
    "for id = start_index:2:end_index \n",
    "    # save the data into different arrays\n",
    "    (point_data, intensity_data, R, t, pose) = data_parser(id)\n",
    "    plot_3D_pointcloud(point_data[1,:], point_data[2,:], point_data[3,:], limits, intensity_data) \n",
    "end\n",
    "\n",
    "#=\n",
    "This plot could take 2 minutes or more to output\n",
    "Don't wait any longer than 7 minutes.\n",
    "=#\n",
    "plot!()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e99526",
   "metadata": {},
   "source": [
    "We have multiple LiDAR images of something, but what that something might be is hard to say. To unravel this mystery, we're going to step back and process just one packet of LiDAR data before we engage with all of them again.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82263db",
   "metadata": {},
   "outputs": [],
   "source": [
    " #=\n",
    "This cell plots the robot at time 13 in the world frame\n",
    "=#\n",
    "(point_data, intensity_data, R, t, pose) = data_parser(end_index) \n",
    "\n",
    "# Build an arrow to indicate the robots position and orientation\n",
    "(pos, u, v) = robot_arrow(pose);\n",
    "\n",
    "# Plot the point cloud and white arrow representing the robot's pose\n",
    "plot()  \n",
    "plot_2D_robot(pos[1,:], pos[2,:], limits, (u,v))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1477810e",
   "metadata": {},
   "source": [
    "The white arrow indicates the position and orientation of the robot. Now that we know the pose of Cassie, let‚Äôs also plot the raw point cloud in the same plot and see if the rings of the point cloud are consistent with Cassie's pose (i.e., position and orientation).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8d811c",
   "metadata": {},
   "outputs": [],
   "source": [
    "(point_data, intensity_data, R, t, pose) = data_parser(end_index)\n",
    "\n",
    "# Plot the 3D point cloud\n",
    "# be patient with the time on this too! \n",
    "# shouldn't take longer than 3 mins\n",
    "plot_3D_pointcloud(point_data[1,:], point_data[2,:], point_data[3,:], limits, intensity_data) \n",
    "plot!()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b02eb9c",
   "metadata": {},
   "source": [
    "Take a close look at the plot you have just generated. **The LiDAR is mounted on top of the robot and the concentric circles you see in the LiDAR points should be centered about the robot.** What we see, instead, is that the data is translated and rotated with respect to the robot. We need to fix that by applying a homogeneous transformation to the point cloud data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2812f4",
   "metadata": {},
   "source": [
    "**You will help achieve this by building the affine transformation matrix,** `H`**:**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce426daf",
   "metadata": {},
   "source": [
    "#### ****H = \\begin{bmatrix} R & t \\\\ 0 & 1 \\end{bmatrix}****\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64407a8f",
   "metadata": {},
   "source": [
    "**where‚Ä¶**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6087062a",
   "metadata": {},
   "source": [
    "* `R` **is the given **3 √ó 3** rotation matrix**\n",
    "* `t` **is the given **3 √ó 1** translation vector**\n",
    "* ****0** is a **1 √ó 3** row vector of zeros**\n",
    "* ****1** is just the number one**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13cc3afc",
   "metadata": {},
   "source": [
    "üí°Remember:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eabcfd7",
   "metadata": {},
   "source": [
    "* Name your matrix `H`\n",
    "* `R` and `t` have already been created for you by the data parser in the above cell!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb9510f",
   "metadata": {},
   "outputs": [],
   "source": [
    "H = [R t;zeros(1,3) 1]",
    "is_it_correct_check1 = isapprox(H[:,1],[0.223755642141881,-0.968392974489662,-0.110220050665654,0.0], atol = 1e-3) ? \"Yes\" : \"No\"\nis_it_correct_check2 = isapprox(H[:,4],[2.52669466213533,-0.957786861851155,1.4354495810566,1.0], atol = 1e-3) ? \"Yes\" : \"No\"\n\n\n@show is_it_correct_check1;¬†\n@show is_it_correct_check2;is_it_correct_check1 = isapprox(H[:,1],[0.223755642141881,-0.968392974489662,-0.110220050665654,0.0], atol = 1e-3) ? \"Yes\" : \"No\"\nis_it_correct_check2 = isapprox(H[:,4],[2.52669466213533,-0.957786861851155,1.4354495810566,1.0], atol = 1e-3) ? \"Yes\" : \"No\"\n\n\n@show is_it_correct_check1;¬†\n@show is_it_correct_check2;is_it_correct_check1 = isapprox(H[:,1],[0.223755642141881,-0.968392974489662,-0.110220050665654,0.0], atol = 1e-3) ? \"Yes\" : \"No\"\nis_it_correct_check2 = isapprox(H[:,4],[2.52669466213533,-0.957786861851155,1.4354495810566,1.0], atol = 1e-3) ? \"Yes\" : \"No\"\n\n\n@show is_it_correct_check1;¬†\n@show is_it_correct_check2;is_it_correct_check1 = isapprox(H[:,1],[0.223755642141881,-0.968392974489662,-0.110220050665654,0.0], atol = 1e-3) ? \"Yes\" : \"No\"\nis_it_correct_check2 = isapprox(H[:,4],[2.52669466213533,-0.957786861851155,1.4354495810566,1.0], atol = 1e-3) ? \"Yes\" : \"No\"\n\n\n@show is_it_correct_check1;¬†\n@show is_it_correct_check2;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94325997",
   "metadata": {},
   "source": [
    "In the cell below, we are using your transformation matrix, `H`, to transform the point cloud data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea75636",
   "metadata": {},
   "outputs": [],
   "source": [
    "#= \n",
    "affine transformation function performs the same actions you did in Task 1\n",
    "It multiplies the transformation matrix, H, by the homogenized original data\n",
    "Remember that homogenized just means a 1 has been appended to each point\n",
    "=#\n",
    "transformed_points = affine_transform(point_data, H)\n",
    "\n",
    "println(\"Can you now see that the LiDAR rings are more centered about the robot?\")\n",
    "println(\"It should now look like the robot is facing the data it just collected.\")\n",
    "println(\"Previously, it may have looked like the robot took some data and then moved.\")\n",
    "\n",
    "# Visualize in 3D point cloud\n",
    "plot() \n",
    "plot_3D_pointcloud(transformed_points[1,:], transformed_points[2,:], \n",
    "                    transformed_points[3,:], limits, intensity_data)\n",
    "\n",
    "# Add robot pose to the plot \n",
    "plot_2D_robot(pos[1,:], pos[2,:], limits, (u,v))\n",
    "plot!()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f72af9",
   "metadata": {},
   "source": [
    "Task 3, Part B\n",
    "--------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80543c3a",
   "metadata": {},
   "source": [
    "#### **Building a map and gif and fusing different LiDAR scans!**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e845b952",
   "metadata": {},
   "source": [
    "We now understand how to go from a sensor frame to a world frame. We will build a map by fusing data over multiple time periods. As you will notice from the figure you just made for one second of data, LiDAR scans collected over 1 second are not enough to give us full understanding of the scene and we therefore need to fuse multiple scans together for a more vivid picture. As much as we would like to give you the full data set (3 minutes of data), due to time constraints, we are going to have you work with five seconds (time = 9 to 13 seconds) of data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce38e3d",
   "metadata": {},
   "source": [
    "However, **one takeaway from this problem should be that the robot is continuously moving, and we need to compensate for its motion with an appropriate transformation matrix that converts the LiDAR data in the sensor frame to LiDAR data in the world frame. The transformation has to be continuously estimated in real-time on the robot.** That part of the problem you can learn about in ROB 330, ROB 501, and ROB 530. There is an entire research area that focuses on calculating the best approximate transformations from the moving LiDAR to the fixed world frame.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7077118b",
   "metadata": {},
   "source": [
    "**Your job is to add code to the for loop that allows us to iterate over all point clouds over the time intervals from 9 to 13.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbde91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_index = 9\n",
    "end_index  = 13\n",
    "Plots.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87864814",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=\n",
    "Code Skeleton : Build an animation!\n",
    "Be patient with the gif! \n",
    "You may need to close some tabs and free\n",
    "up your local RAM.\n",
    "=#\n",
    "\n",
    "anim = @animate for id = start\\_index:end\\_index \n",
    " transformed\\_points = [];\n",
    "\n",
    " \n",
    " #= \n",
    " YOUR CODE HERE (3 lines described below)\n",
    " \n",
    " Line 1. Parse the data for the i-th time interval (id) using the \n",
    " data\\_parser() function. Store it in the arrays with the same name \n",
    " like we did before in the example before Part A.\n",
    "\n",
    " Line 2. Build the affine transformation matrix, H, from Part A\n",
    "\n",
    " Line 3. Transform your point cloud using the affine transformation function\n",
    " and store the result in a variable named transformed\\_points as \n",
    " exemplified in Part A\n",
    " =#\n",
    " \n",
    " plot\\_3D\\_pointcloud(transformed\\_points[1,:], transformed\\_points[2,:], \n",
    " transformed\\_points[3,:],limits, intensity\\_data)\n",
    " \n",
    " # A Hack for plotting the position\n",
    " if(id!=start\\_index)\n",
    " # Plot your previous position with a black dot everytime except the first\n",
    " (point\\_data, intensity\\_data, R, t, prev\\_pose) = data\\_parser(id-1); \n",
    " plot\\_3D\\_robot([prev\\_pose[1,1]],[prev\\_pose[2,1]],\n",
    " [prev\\_pose[3,1]], seriescolor=:black)\n",
    " end\n",
    " \n",
    " plot\\_3D\\_robot([pose[1,1]],[pose[2,1]],[pose[3,1]],seriescolor=:white)\n",
    "\n",
    " prev\\_pose = copy(pose);\n",
    "end\n",
    "\n",
    "# replace \"yourName\" with your actual first and last name (no spaces)\n",
    "gif(anim, \"yourName\\_RobotGIF.gif\", fps = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398e30a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=\nCode Skeleton : Build an animation!\nBe patient with the gif! \nYou may need to close some tabs and free\nup your local RAM.\n=#\n\nanim = @animate for id = start_index:end_index \n    transformed_points = [];\n\n    (point_data, intensity_data, R, t, pose) = data_parser(id)\n    H = [R t;zeros(1,3) 1]\n    transformed_points = affine_transform(point_data, H)\n    #= \n      YOUR CODE HERE (3 lines described below)\n      \n      Line 1. Parse the data for the i-th time interval (id) using the \n        data_parser() function. Store it in the arrays with the same name \n        like we did before in the example before Part A.\n\n      Line 2. Build the affine transformation matrix, H, from Part A\n\n      Line 3. Transform your point cloud using the affine transformation function\n        and store the result in a variable named transformed_points as \n        exemplified in Part A\n    =#\n    \n    plot_3D_pointcloud(transformed_points[1,:], transformed_points[2,:], \n            transformed_points[3,:],limits, intensity_data)\n    \n    # A Hack for plotting the position\n    if(id!=start_index)\n        # Plot your previous position with a black dot everytime except the first\n        (point_data, intensity_data, R, t, prev_pose) = data_parser(id-1); \n        plot_3D_robot([prev_pose[1,1]],[prev_pose[2,1]],\n              [prev_pose[3,1]], seriescolor=:black)\n    end\n     \n    plot_3D_robot([pose[1,1]],[pose[2,1]],[pose[3,1]],seriescolor=:white)\n\n    prev_pose = copy(pose);\nend\n\n# replace \"yourName\" with your actual first and last name (no spaces)\ngif(anim, \"kaichiweng_RobotGIF.gif\", fps = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63043b51",
   "metadata": {},
   "source": [
    "You should see the white dot, Cassie, moving within the map while everything else in the map stays fixed (*like the stairs*)!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c1dc01",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34c663e",
   "metadata": {},
   "source": [
    "üéâ Congrats! You completed your first ROB101 project and applied your knowledge to real world data! ‚ú®üëèüèΩ\n",
    "------------------------------------------------------------------------------------------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c5cd5a",
   "metadata": {},
   "source": [
    "![](https://media0.giphy.com/media/v1.Y2lkPTc5MGI3NjExMDNycHF3eWszcjhwZHM1OXZ1NTdqd3BtdmVvZjZydHQ2c293YmowZiZlcD12MV9naWZzX3NlYXJjaCZjdD1n/3gpfkdQIunv5C/200.gif)"
   ]
  }
 ],
 "metadata": {
  "authors": [
   "Greg Werner"
  ],
  "kernelspec": {
   "display_name": "Julia",
   "language": "julia",
   "name": "julia"
  },
  "language_info": {
   "name": "julia"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}